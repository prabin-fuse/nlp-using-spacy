{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spacy:\n",
    "- Spacy is free, open-source library for advanced NLP in Python.\n",
    "- made for :\n",
    "    - production use\n",
    "    - information extraction\n",
    "    - Natural language understanding systems\n",
    "    - pre-process text for deep learning\n",
    "\n",
    "## - Spacy's Statistical Models\n",
    "## - Spacy's Processing Pipeline\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Features of Spacy:\n",
    "| Name                          | Description                                                                                     |\n",
    "|-------------------------------|-------------------------------------------------------------------------------------------------|\n",
    "| Tokenization                  | Segmenting text into words, punctuations marks etc.                                              |\n",
    "| Part-of-speech (POS) Tagging | Assigning word types to tokens, like verb or noun.                                               |\n",
    "| Dependency Parsing            | Assigning syntactic dependency labels, describing the relations between individual tokens.      |\n",
    "| Lemmatization                 | Assigning the base forms of words. For example, the lemma of “was” is “be”, and the lemma of “rats” is “rat”. |\n",
    "| Sentence Boundary Detection   | Finding and segmenting individual sentences.                                                      |\n",
    "| Named Entity Recognition (NER)| Labelling named “real-world” objects, like persons, companies or locations.                      |\n",
    "| Entity Linking (EL)          | Disambiguating textual entities to unique identifiers in a knowledge base.                       |\n",
    "| Similarity                    | Comparing words, text spans and documents and how similar they are to each other.                 |\n",
    "| Text Classification          | Assigning categories or labels to a whole document, or parts of a document.                        |\n",
    "| Rule-based Matching          | Finding sequences of tokens based on their texts and linguistic annotations, similar to regular expressions. |\n",
    "| Training                      | Updating and improving a statistical model’s predictions.                                         |\n",
    "| Serialization                | Saving objects to files or byte strings.                                                          |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Statistical Models in Spacy:\n",
    "- en_core_web_sm\n",
    "- en_core_web_md\n",
    "- en_core_web_lg\n",
    "\n",
    "It need to be load by using ```spacy.load()```\n",
    "- It returns a Language callable object, commonly called nlp."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting en-core-web-sm==3.7.1\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.7.1/en_core_web_sm-3.7.1-py3-none-any.whl (12.8 MB)\n",
      "     ---------------------------------------- 12.8/12.8 MB 6.1 MB/s eta 0:00:00\n",
      "Requirement already satisfied: spacy<3.8.0,>=3.7.2 in c:\\users\\dell\\anaconda3\\envs\\myenvbb\\lib\\site-packages (from en-core-web-sm==3.7.1) (3.7.4)\n",
      "Requirement already satisfied: numpy>=1.19.0 in c:\\users\\dell\\appdata\\roaming\\python\\python310\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.22.1)\n",
      "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in c:\\users\\dell\\anaconda3\\envs\\myenvbb\\lib\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (6.4.0)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\dell\\anaconda3\\envs\\myenvbb\\lib\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (24.0)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in c:\\users\\dell\\anaconda3\\envs\\myenvbb\\lib\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.0.10)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in c:\\users\\dell\\anaconda3\\envs\\myenvbb\\lib\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.0.8)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in c:\\users\\dell\\anaconda3\\envs\\myenvbb\\lib\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.4.8)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in c:\\users\\dell\\anaconda3\\envs\\myenvbb\\lib\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.0.5)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in c:\\users\\dell\\anaconda3\\envs\\myenvbb\\lib\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.31.0)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in c:\\users\\dell\\appdata\\roaming\\python\\python310\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (4.62.3)\n",
      "Requirement already satisfied: typer<0.10.0,>=0.3.0 in c:\\users\\dell\\anaconda3\\envs\\myenvbb\\lib\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.9.4)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in c:\\users\\dell\\anaconda3\\envs\\myenvbb\\lib\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.0.12)\n",
      "Requirement already satisfied: setuptools in c:\\users\\dell\\anaconda3\\envs\\myenvbb\\lib\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (63.2.0)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\dell\\anaconda3\\envs\\myenvbb\\lib\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.1.4)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in c:\\users\\dell\\anaconda3\\envs\\myenvbb\\lib\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.7.1)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in c:\\users\\dell\\anaconda3\\envs\\myenvbb\\lib\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.0.9)\n",
      "Requirement already satisfied: thinc<8.3.0,>=8.2.2 in c:\\users\\dell\\anaconda3\\envs\\myenvbb\\lib\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (8.2.3)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in c:\\users\\dell\\anaconda3\\envs\\myenvbb\\lib\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.4.0)\n",
      "Requirement already satisfied: weasel<0.4.0,>=0.1.0 in c:\\users\\dell\\anaconda3\\envs\\myenvbb\\lib\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.3.4)\n",
      "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in c:\\users\\dell\\anaconda3\\envs\\myenvbb\\lib\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.1.2)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in c:\\users\\dell\\anaconda3\\envs\\myenvbb\\lib\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.0.10)\n",
      "Requirement already satisfied: language-data>=1.2 in c:\\users\\dell\\anaconda3\\envs\\myenvbb\\lib\\site-packages (from langcodes<4.0.0,>=3.2.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.2.0)\n",
      "Requirement already satisfied: pydantic-core==2.18.2 in c:\\users\\dell\\anaconda3\\envs\\myenvbb\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.18.2)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in c:\\users\\dell\\anaconda3\\envs\\myenvbb\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.6.0)\n",
      "Requirement already satisfied: typing-extensions>=4.6.1 in c:\\users\\dell\\anaconda3\\envs\\myenvbb\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (4.9.0)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\dell\\appdata\\roaming\\python\\python310\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.26.8)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\dell\\appdata\\roaming\\python\\python310\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.0.11)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\dell\\anaconda3\\envs\\myenvbb\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\dell\\appdata\\roaming\\python\\python310\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2021.10.8)\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in c:\\users\\dell\\anaconda3\\envs\\myenvbb\\lib\\site-packages (from thinc<8.3.0,>=8.2.2->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.1.4)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.7.8 in c:\\users\\dell\\anaconda3\\envs\\myenvbb\\lib\\site-packages (from thinc<8.3.0,>=8.2.2->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.7.11)\n",
      "Requirement already satisfied: colorama in c:\\users\\dell\\anaconda3\\envs\\myenvbb\\lib\\site-packages (from tqdm<5.0.0,>=4.38.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.4.6)\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in c:\\users\\dell\\anaconda3\\envs\\myenvbb\\lib\\site-packages (from typer<0.10.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (8.1.7)\n",
      "Requirement already satisfied: cloudpathlib<0.17.0,>=0.7.0 in c:\\users\\dell\\anaconda3\\envs\\myenvbb\\lib\\site-packages (from weasel<0.4.0,>=0.1.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.16.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\dell\\anaconda3\\envs\\myenvbb\\lib\\site-packages (from jinja2->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.1.2)\n",
      "Requirement already satisfied: marisa-trie>=0.7.7 in c:\\users\\dell\\anaconda3\\envs\\myenvbb\\lib\\site-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.1.1)\n",
      "Installing collected packages: en-core-web-sm\n",
      "Successfully installed en-core-web-sm-3.7.1\n",
      "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
      "You can now load the package via spacy.load('en_core_web_sm')\n"
     ]
    }
   ],
   "source": [
    "# Firstly, download the models as required:\n",
    "!python -m spacy download en_core_web_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: spacy in c:\\users\\dell\\anaconda3\\envs\\myenvbb\\lib\\site-packages (3.7.4)\n",
      "Requirement already satisfied: weasel<0.4.0,>=0.1.0 in c:\\users\\dell\\anaconda3\\envs\\myenvbb\\lib\\site-packages (from spacy) (0.3.4)\n",
      "Requirement already satisfied: numpy>=1.19.0 in c:\\users\\dell\\appdata\\roaming\\python\\python310\\site-packages (from spacy) (1.22.1)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in c:\\users\\dell\\anaconda3\\envs\\myenvbb\\lib\\site-packages (from spacy) (2.0.8)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in c:\\users\\dell\\anaconda3\\envs\\myenvbb\\lib\\site-packages (from spacy) (2.7.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\dell\\anaconda3\\envs\\myenvbb\\lib\\site-packages (from spacy) (3.1.4)\n",
      "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in c:\\users\\dell\\anaconda3\\envs\\myenvbb\\lib\\site-packages (from spacy) (1.1.2)\n",
      "Requirement already satisfied: setuptools in c:\\users\\dell\\anaconda3\\envs\\myenvbb\\lib\\site-packages (from spacy) (63.2.0)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in c:\\users\\dell\\anaconda3\\envs\\myenvbb\\lib\\site-packages (from spacy) (1.0.5)\n",
      "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in c:\\users\\dell\\anaconda3\\envs\\myenvbb\\lib\\site-packages (from spacy) (6.4.0)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in c:\\users\\dell\\anaconda3\\envs\\myenvbb\\lib\\site-packages (from spacy) (3.4.0)\n",
      "Requirement already satisfied: typer<0.10.0,>=0.3.0 in c:\\users\\dell\\anaconda3\\envs\\myenvbb\\lib\\site-packages (from spacy) (0.9.4)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in c:\\users\\dell\\anaconda3\\envs\\myenvbb\\lib\\site-packages (from spacy) (3.0.9)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in c:\\users\\dell\\anaconda3\\envs\\myenvbb\\lib\\site-packages (from spacy) (1.0.10)\n",
      "Requirement already satisfied: thinc<8.3.0,>=8.2.2 in c:\\users\\dell\\anaconda3\\envs\\myenvbb\\lib\\site-packages (from spacy) (8.2.3)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in c:\\users\\dell\\anaconda3\\envs\\myenvbb\\lib\\site-packages (from spacy) (3.0.12)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in c:\\users\\dell\\appdata\\roaming\\python\\python310\\site-packages (from spacy) (4.62.3)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in c:\\users\\dell\\anaconda3\\envs\\myenvbb\\lib\\site-packages (from spacy) (2.31.0)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\dell\\anaconda3\\envs\\myenvbb\\lib\\site-packages (from spacy) (24.0)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in c:\\users\\dell\\anaconda3\\envs\\myenvbb\\lib\\site-packages (from spacy) (2.4.8)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in c:\\users\\dell\\anaconda3\\envs\\myenvbb\\lib\\site-packages (from spacy) (2.0.10)\n",
      "Requirement already satisfied: language-data>=1.2 in c:\\users\\dell\\anaconda3\\envs\\myenvbb\\lib\\site-packages (from langcodes<4.0.0,>=3.2.0->spacy) (1.2.0)\n",
      "Requirement already satisfied: pydantic-core==2.18.2 in c:\\users\\dell\\anaconda3\\envs\\myenvbb\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (2.18.2)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in c:\\users\\dell\\anaconda3\\envs\\myenvbb\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (0.6.0)\n",
      "Requirement already satisfied: typing-extensions>=4.6.1 in c:\\users\\dell\\anaconda3\\envs\\myenvbb\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (4.9.0)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\dell\\appdata\\roaming\\python\\python310\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (1.26.8)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\dell\\appdata\\roaming\\python\\python310\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (2.0.11)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\dell\\appdata\\roaming\\python\\python310\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (2021.10.8)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\dell\\anaconda3\\envs\\myenvbb\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (3.4)\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in c:\\users\\dell\\anaconda3\\envs\\myenvbb\\lib\\site-packages (from thinc<8.3.0,>=8.2.2->spacy) (0.1.4)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.7.8 in c:\\users\\dell\\anaconda3\\envs\\myenvbb\\lib\\site-packages (from thinc<8.3.0,>=8.2.2->spacy) (0.7.11)\n",
      "Requirement already satisfied: colorama in c:\\users\\dell\\anaconda3\\envs\\myenvbb\\lib\\site-packages (from tqdm<5.0.0,>=4.38.0->spacy) (0.4.6)\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in c:\\users\\dell\\anaconda3\\envs\\myenvbb\\lib\\site-packages (from typer<0.10.0,>=0.3.0->spacy) (8.1.7)\n",
      "Requirement already satisfied: cloudpathlib<0.17.0,>=0.7.0 in c:\\users\\dell\\anaconda3\\envs\\myenvbb\\lib\\site-packages (from weasel<0.4.0,>=0.1.0->spacy) (0.16.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\dell\\anaconda3\\envs\\myenvbb\\lib\\site-packages (from jinja2->spacy) (2.1.2)\n",
      "Requirement already satisfied: marisa-trie>=0.7.7 in c:\\users\\dell\\anaconda3\\envs\\myenvbb\\lib\\site-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy) (1.1.1)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<spacy.lang.en.English at 0x1840cebbe50>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "!pip install spacy\n",
    "import spacy\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "nlp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or, we can directly import form the ```spacy.lang.en``` for English"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the english language class\n",
    "from spacy.lang.en import English\n",
    "\n",
    "#create the nlp object\n",
    "nlp = English()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Doc Object\n",
    "- You can instantiate a Doc object by calling the Language object with the input string as an argument:\n",
    "- For instance, you iterated over the Doc object with a list comprehension that produces a series of Token objects.\n",
    "### Token Object:\n",
    "- for example word or a punctuation character\n",
    "- To get a token at specific position, you can index into the doc.\n",
    "- Token objects also provide various attributes that let you access more information about the tokens.\n",
    "    - On each Token object, you called the .text attribute to get the text contained within that token."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "spacy.tokens.doc.Doc"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "introduction_doc = nlp(\"This tutorial is about Natural Language Processing in spaCy.\")\n",
    "type(introduction_doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['This',\n",
       " 'tutorial',\n",
       " 'is',\n",
       " 'about',\n",
       " 'Natural',\n",
       " 'Language',\n",
       " 'Processing',\n",
       " 'in',\n",
       " 'spaCy',\n",
       " '.']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[token.text for token in introduction_doc]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "This"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Index into Doc to get specific token:\n",
    "token1 =introduction_doc[0]\n",
    "token1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Span Object:\n",
    "- A span object is a slice of the document consisting of one or more tokens.\n",
    "- It's only a view of the Doc and doesn't contain any data itself.\n",
    "- To create a span, you can use python's slice notation.\n",
    "- For example:\n",
    "    - 1:3 will create a slice starting from the token at position 1, up to – but not including! – the token at position 3.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "are you\n"
     ]
    }
   ],
   "source": [
    "doc = nlp(\"How are you doing?\")\n",
    "\n",
    "# A slice from the doc object is a span object\n",
    "span = doc[1:3]\n",
    "\n",
    "# to get span text, use .text attribute\n",
    "print(span.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lexical Attributes\n",
    "\n",
    "Some available token attributes:\n",
    "\n",
    "- ```i``` is the index of the token within the parent document.\n",
    "- ```text``` return the token text\n",
    "- ```is_alpha``` return boolean values indicating whether the token consists of alphabetic character\n",
    "    - example: the word \"ten\"\n",
    "- ```is_punct``` return boolean whether token is punctuation\n",
    "    - example: \"one, zero\"\n",
    "- ```like_num``` returns boolean if it is like number\n",
    "    - example: a token \"10\"\n",
    "    \n",
    "These attributes are also called lexical attributes: they refer to the entry in the vocabulary and don't depend on the token's context."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Indexes =  [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]\n",
      "Text =  ['Hello', 'sir', ',', 'here', 'is', 'you', 'coffee', '!', 'It', 'costs', '$', '10']\n",
      "is_alpha =  [True, True, False, True, True, True, True, False, True, True, False, False]\n",
      "is_punct =  [False, False, True, False, False, False, False, True, False, False, False, False]\n",
      "like_num =  [False, False, False, False, False, False, False, False, False, False, False, True]\n"
     ]
    }
   ],
   "source": [
    "# Create doc object:\n",
    "doc = nlp(\"Hello sir, here is you coffee! It costs $10\")\n",
    "\n",
    "# lexical attributes: i, text\n",
    "print(\"Indexes = \",[token.i for token in doc])\n",
    "print(\"Text = \", [token.text for token in doc])\n",
    "\n",
    "# lexical attributes: is_alpha, is_punct, like_num\n",
    "print(\"is_alpha = \", [token.is_alpha for token in doc])\n",
    "print(\"is_punct = \", [token.is_punct for token in doc])\n",
    "print(\"like_num = \", [token.like_num for token in doc])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage found : 60\n",
      "Percentage found : 4\n"
     ]
    }
   ],
   "source": [
    "# Example of lexical attribute: Give the numbers infront of percentage:\n",
    "\n",
    "# creating the doc object:\n",
    "doc = nlp(\n",
    "    \"In 1990, more than 60% of people in East Asia were in extreme poverty. \"\n",
    "    \"Now less than 4% are.\"\n",
    ")\n",
    "\n",
    "for token in doc:\n",
    "    if token.like_num:\n",
    "        next_token = doc[token.i + 1]\n",
    "\n",
    "        if next_token.text == \"%\":\n",
    "            print(\"Percentage found :\", token)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Doc Object by reading the file.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Hello', ',', 'this', 'is', 'just', 'the', 'dummy', 'text', 'file', 'to', 'test', 'the', 'document', 'object', 'of', 'the', 'Spacy', 'library', '.']\n"
     ]
    }
   ],
   "source": [
    "import pathlib\n",
    "file_name = \"../test.txt\"\n",
    "introduction_doc = nlp(pathlib.Path(file_name).read_text(encoding=\"utf-8\"))\n",
    "print ([token.text for token in introduction_doc])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sentence Detection:\n",
    "- locate where sentence start and end in a given text\n",
    "- divides text into linguistically meaningful units\n",
    "- useful for \"POS tagging\" and \"Named-Entity Recognition\"\n",
    "- ```.sents``` property is used to extract sentence from doc object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Gus Proto is a Python developer currently working for a London-based Fintech company., He is interested in learning Natural Language Processing.]\n"
     ]
    }
   ],
   "source": [
    "about_text = (\n",
    "    \"Gus Proto is a Python developer currently\"\n",
    "    \" working for a London-based Fintech\"\n",
    "    \" company. He is interested in learning\"\n",
    "    \" Natural Language Processing.\"\n",
    ")\n",
    "\n",
    "#create a doc object:\n",
    "about_doc = nlp(about_text)\n",
    "\n",
    "# use .sents property to get the sentence from the document\n",
    "sentences = list(about_doc.sents)\n",
    "print(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gus Proto is a Python...\n",
      "He is interested in learning...\n"
     ]
    }
   ],
   "source": [
    "#Iterate over each sentence\n",
    "for sentence in sentences:\n",
    "    print(f\"{sentence[:5]}...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenvbb",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
